
# HIVE

Apache Hive — это инструмент для работы с большими данными, который позволяет писать запросы на SQL-подобном языке (HiveQL) для анализа данных, хранящихся в Hadoop Distributed File System (HDFS) или других совместимых хранилищах, таких как Amazon S3. Hive переводит запросы HiveQL в задачи MapReduce, Apache Tez или Apache Spark, чтобы обработать их на кластере.

## Основные особенности Hive:
1. **SQL-подобный язык**:
   - HiveQL (Hive Query Language) позволяет писать запросы, которые похожи на стандартный SQL.
   - Поддерживаются операции SELECT, JOIN, GROUP BY, UNION и другие.
2. **Работа с большими данными**:
   - Оптимизирован для обработки огромных объемов данных.
   - Использует параллельные вычисления с помощью MapReduce, Tez или Spark.
3. **Хранилище данных (Data Warehousing)**:
   - Hive часто используется для построения хранилищ данных и аналитики.
   - Подходит для анализа данных "постфактум" (batch processing), но не для потоковой обработки в реальном времени.
4. **Интеграция с Hadoop**:
   - Поддерживает HDFS для хранения данных и YARN для управления ресурсами.
5. **Широкая поддержка форматов данных**:
   - Работает с файлами в формате CSV, JSON, Parquet, ORC и другими.
6. **Таблицы и схемы**:
   - Hive использует метаданные, чтобы управлять таблицами и базами данных. Эти метаданные хранятся в Metastore, который может быть на базе MySQL, PostgreSQL и других баз данных.

<image src="https://github.com/NikGerasimovich/Data-engineering/blob/main/Hive/IMAGE/hive%20arch1.png" alt="HIVE">

## Основные компоненты:
1. **User Interface (UI)**  
   Это интерфейс, через который пользователи взаимодействуют с Hive.  
   Популярные варианты интерфейса:  
   - CLI (Command Line Interface).  
   - Beeline — клиент для JDBC-подключений.  
2. **Driver**  
   Обрабатывает запросы HiveQL:  
   - **Parser**: Проверяет синтаксис и семантику запроса.  
   - **Query Compiler**: Преобразует HiveQL в логический план выполнения.  
   - **Optimizer**: Оптимизирует план выполнения (например, объединяет несколько операций в одну).  
   - **Execution Engine**: Передаёт задания на выполнение в движок (MapReduce, Tez или Spark).  
3. **Metastore**  
   Центральный компонент, который хранит метаданные о:  
   - Таблицах (имя, схема, формат хранения).  
   - Колонках и их типах данных.  
   - Партициях.  
   - Местоположении данных на HDFS.  
   Метаданные обычно хранятся в реляционной базе данных (например, MySQL или PostgreSQL).  
4. **Execution Engine**  
   Выполняет задачи, сгенерированные драйвером. Может использовать:  
   - **MapReduce** (по умолчанию в старых версиях).  
   - **Tez** (быстрее, чем MapReduce).  
   - **Spark** (ещё более производительный вариант).  
5. **Storage (Хранилище)**  
   Данные Hive хранятся на HDFS или других совместимых системах (например, Amazon S3).  

| Название компонента | Описание |
|----------------------|----------|
| **UI (Пользовательский интерфейс)** | Позволяет выполнять запросы и команды в Hive: CLI, Beeline, Hive Web UI |
| **Meta Store (Хранилище метаданных)** | Хранит метаданные для таблиц Hive |
| **Hive QL Process Engine** | Обрабатывает запросы HiveQL |
| **Execution Engine** | Генерирует план задач MapReduce |
| **HDFS или HBASE** | Методы хранения данных |

---

## **Объекты Hive**

### 1. **Таблицы** 
- Основной объект для хранения данных.  
- Делятся на:
  - **Управляемые таблицы** (Managed): Hive контролирует их данные и схему. Удаление таблицы удаляет и данные.  
  - **Внешние таблицы** (External): Hive только управляет метаданными, данные остаются во внешнем хранилище.  

**Пример создания таблицы**:  
```sql
CREATE TABLE managed_table (
   id INT,
   name STRING,
   age INT
)
STORED AS ORC;
```

**Пример создания внешней таблицы**:  
```sql
CREATE EXTERNAL TABLE external_table (
   id INT,
   name STRING
)
STORED AS PARQUET
LOCATION '/user/hive/external_data/';
```

### 2. **Партиции (Partitions)**  
Партиции позволяют разбивать таблицу на логические сегменты на основе значения одной или нескольких колонок. Это улучшает производительность, так как Hive читает только нужные разделы.  

**Пример таблицы с партициями**:  
```sql
CREATE TABLE sales_partitioned (
    product_id INT,
    sales_amount FLOAT
)
PARTITIONED BY (sale_date STRING)
STORED AS PARQUET;
```

**Добавление данных в партицию**:  
```sql
INSERT INTO sales_partitioned PARTITION (sale_date='2024-12-01')
VALUES (101, 500.0);
```

---

## **Примеры HiveQL**
1. **Создание таблицы**:  
```sql
CREATE TABLE sales (
   id INT,
   product STRING,
   amount FLOAT,
   sale_date DATE
)
STORED AS PARQUET;
```

2. **Загрузка данных**:  
```sql
LOAD DATA INPATH '/user/hadoop/sales_data.csv' INTO TABLE sales;
```

3. **Запрос данных**:  
```sql
SELECT product, SUM(amount) AS total_sales
FROM sales
GROUP BY product;
```

---

## **Преимущества Hive**
- Простота использования благодаря SQL-подобному языку.
- Масштабируемость для работы с петабайтами данных.
- Интеграция с экосистемой Hadoop.
- Богатая экосистема инструментов для расширения функциональности.

## **Ограничения Hive**
1. Не подходит для приложений реального времени (высокая задержка из-за обработки batch-заданий).
2. Медленнее, чем специализированные базы данных (например, Amazon Redshift или Snowflake) при определенных сценариях.
3. Ограниченная поддержка транзакций и обновлений данных.


# HBase

## Apache HBase — это распределённая, масштабируемая, NoSQL база данных, построенная поверх Hadoop Distributed File System (HDFS). Она предназначена для обработки огромных объёмов данных с низкой задержкой, обеспечивая гибкость и производительность для работы с нереляционными данными.

## Основные особенности HBase:
1. Колонко-ориентированное хранилище:
   - Данные хранятся в виде строк и колонок, но не фиксированы по количеству столбцов, что даёт гибкость при работе с неструктурированными данными.
2. Массивные данные:
   - Предназначена для хранения и обработки петабайтных объёмов данных.
3. Высокая производительность:
   - Оптимизирована для работы с чтением и записью в режиме реального времени.
4. Интеграция с Hadoop:
   - Использует HDFS как основное хранилище данных. Интегрируется с MapReduce, Apache Spark и другими инструментами экосистемы Hadoop.
5. Модели данных:
   - Поддерживает пару ключ-значение (key-value), где ключи используются для быстрой выборки данных.


| **Критерий**               | **Hive**                                           | **HBase**                                       |
|----------------------------|---------------------------------------------------|------------------------------------------------|
| **Тип хранилища**          | Хранилище данных (Data Warehouse)                 | NoSQL база данных                              |
| **Формат данных**          | Статические данные, структурированные             | Динамические данные, полу- и неструктурированные |
| **Обработка данных**       | Batch-процессинг (анализ "постфактум")            | Обработка в реальном времени                   |
| **Интерфейс**              | SQL-подобный язык (HiveQL)                        | API (Java, Python и т.д.)                      |
| **Скорость доступа**       | Высокая задержка, ориентирована на анализ         | Низкая задержка, оптимизирована для записи и чтения |
| **Тип использования**      | Аналитические задачи, агрегация, BI               | Быстрые операции чтения/записи, поиск по ключам |
| **Хранилище**              | Хранит данные в HDFS                              | Хранит данные в HDFS с низкой задержкой        |
| **Пример задачи**          | Суммировать продажи за год                        | Быстро найти информацию о пользователе по ID   |
