# Kafka

## Что такое Apache Kafka?

Apache Kafka — это распределенная платформа для обработки потоков данных в реальном времени. Она используется для публикации, подписки, хранения и обработки данных, поступающих в реальном времени.

<image src="https://github.com/NikGerasimovich/Data-engineering/blob/main/Kafka/IMAGE/kafka-intro.png" alt="Kafkainro">


### Основные особенности Kafka:

- **Высокая производительность**: Kafka поддерживает обработку миллионов сообщений в секунду.
- **Устойчивость к сбоям**: Благодаря репликации данных и распределению по узлам.
- **Масштабируемость**: Легко добавлять узлы для обработки увеличивающегося объёма данных.
- **Гибкость**: Поддерживает множество сценариев, таких как потоковая аналитика, интеграция данных, мониторинг и обработка логов.

## Как работает Kafka

1. **Производители (Producers)** отправляют сообщения в топики Kafka.
2. **Брокеры (Brokers)** хранят сообщения, разделяя их по партициям внутри топиков.
3. **Потребители (Consumers)** считывают сообщения из партиций топиков.
4. **ZooKeeper** (или встроенный механизм Raft) координирует работу кластера и следит за метаданными.

---

# Архитектура Kafka

<image src="https://github.com/NikGerasimovich/Data-engineering/blob/main/Kafka/IMAGE/components-and-concepts-of-apache-kafka-peerbits.webp" alt="component">

### 1. Топики

Основная структура данных Kafka, куда пишутся сообщения. Сообщения в топиках организованы в порядке поступления и записываются в виде логов.

#### Топик (topic) в Apache Kafka
Топик — это основной объект для хранения и организации сообщений. Он действует как логическая категория или поток данных, куда производители (producers) отправляют сообщения, а потребители (consumers) считывают их.

#### Ключевые особенности топиков:
- **Логическая организация данных**: каждый топик представляет собой поток сообщений, связанный с определённым типом данных или событием. Например, топики могут называться `user_signups`, `transactions`, или `logs`.
- **Сегментация по разделам (партициям)**: топики делятся на партиции (partitions), которые позволяют распределить нагрузку и увеличить производительность. Сообщения внутри партиции хранятся в строгом порядке, что упрощает обработку событий.
- **Уникальное имя**: топик идентифицируется уникальным именем внутри кластера Kafka.
- **Хранение данных**: сообщения в топиках сохраняются на диск и доступны в течение заданного времени (по умолчанию 7 дней), независимо от того, были ли они считаны потребителями.

#### Как работают топики:
1. **Производители отправляют сообщения в топик**:
   - Producer указывает имя топика и данные, которые нужно отправить.
   - Kafka автоматически распределяет сообщения по партициям (в зависимости от настроек или ключа сообщения).
2. **Потребители читают сообщения из топика**:
   - ConsumerGroup может подписаться на один или несколько топиков и получать данные.
   - Kafka отслеживает, какие сообщения были прочитаны каждым потребителем.
3. **Данные в партициях**:
   - Сообщения хранятся с уникальным идентификатором — `offset`.
   - `Offset` позволяет потребителям возобновить чтение с определённой точки.

#### Важность топиков:
- **Разделение потоков данных**: каждый топик организует данные по категориям, что упрощает управление потоками сообщений.
- **Масштабируемость**: разделение топиков на партиции позволяет распределять нагрузку между брокерами и потребителями.
- **Гибкость**: несколько приложений могут одновременно подписываться на один топик и обрабатывать сообщения независимо.

---

### 2. Партиции

Топик делится на партиции для масштабируемости. Каждое сообщение в партиции имеет уникальное смещение (offset). 

#### Партиции (partitions) в Apache Kafka
Партиции — это подкатегории внутри топика, которые позволяют разделить данные для улучшения производительности и масштабируемости. Каждая партиция представляет собой упорядоченный лог данных, где сообщения записываются в строгом порядке.

#### Основные особенности партиций:
- **Упорядоченность внутри партиции**: 
  Сообщения записываются и читаются в порядке их поступления.  
  Например, если сообщения A, B и C отправлены в одну партицию, то потребитель прочитает их в порядке A → B → C.
- **Масштабируемость**: 
  Партиции позволяют распределять данные топика по нескольким узлам (брокерам) в кластере Kafka.  
  Чем больше партиций, тем выше производительность, так как данные обрабатываются параллельно.
- **Хранение**: 
  Каждая партиция физически представлена в виде файла на диске у брокера. Данные хранятся до истечения срока хранения (например, 7 дней).
- **Идентификация сообщений**: 
  Каждое сообщение в партиции имеет уникальный `offset`, который используется для отслеживания положения сообщения.

#### Как работают партиции:
1. **Производитель отправляет сообщения**:
   - Kafka распределяет сообщения по партициям.
     - Круговым методом (Round-Robin), если ключ сообщения не указан.
     - По хэшу ключа, если у сообщения есть ключ. Например, сообщения с ключом "User1" всегда попадают в одну и ту же партицию.
2. **Потребитель считывает сообщения**:
   - Каждый потребитель в группе потребителей (Consumer Group) получает доступ к одной или нескольким партициям.
   - Kafka гарантирует, что одно сообщение из партиции обрабатывается только одним потребителем в группе.

#### Важность партиций:
- **Увеличение производительности**: 
  Разделение данных по партициям позволяет нескольким брокерам одновременно обрабатывать сообщения.  
  Производители и потребители могут работать параллельно, что ускоряет обработку данных.
- **Масштабируемость**: 
  Увеличение количества партиций в топике позволяет справляться с ростом данных или увеличением нагрузки.
- **Балансировка нагрузки**: 
  Данные и запросы распределяются между брокерами, снижая нагрузку на один узел.

#### Когда использовать партиции:
- При необходимости обработки больших объёмов данных, распределяя нагрузку между несколькими узлами.
- Для обеспечения упорядоченности сообщений внутри каждой партиции.
- Для горизонтального масштабирования системы (увеличение количества потребителей или производительности).

---

### 3. Брокеры

Kafka-кластер состоит из одного или нескольких брокеров. Каждый брокер отвечает за часть топиков и партиций.

#### Брокеры (brokers) в Apache Kafka
Брокеры — это серверы, которые входят в кластер Kafka и выполняют основную работу по управлению данными. Каждый брокер отвечает за хранение, обработку и доставку сообщений из топиков.

#### Роль брокеров в Kafka:
- **Хранение данных**: брокеры хранят сообщения, публикуемые производителями, и поддерживают их до истечения срока хранения (`retention period`).
- **Обработка запросов**: принимают запросы от производителей на запись данных и от потребителей на чтение данных.
- **Распределение нагрузки**: данные топика (партиции) распределяются между несколькими брокерами для повышения производительности и отказоустойчивости.
- **Обеспечение репликации**: брокеры обеспечивают репликацию данных для повышения отказоустойчивости. Один из брокеров назначается лидером для каждой партиции, а остальные являются репликами.

#### Основные характеристики брокеров:
- **Идентификация**: каждый брокер в кластере имеет уникальный ID (например, `broker-1`, `broker-2`).
- **Распределение данных**: каждый брокер обслуживает одну или несколько партиций. Например:  
  - Partition 0 → Broker 1  
  - Partition 1 → Broker 2  
  - Partition 2 → Broker 3
- **Лидерство**: для каждой партиции один брокер назначается лидером, который обрабатывает все запросы на запись и чтение. Остальные брокеры хранят копии данных в качестве реплик.
- **Обеспечение отказоустойчивости**: если лидер партиции выходит из строя, один из брокеров с репликой становится новым лидером.

#### Архитектура с брокерами:
**Пример:**  
Топик `orders` имеет 3 партиции. Кластер состоит из 3 брокеров:  
- **Broker 1**  
- **Broker 2**  
- **Broker 3**  

Распределение партиций:  
- Partition 0 → Leader: Broker 1, Replica: Broker 2  
- Partition 1 → Leader: Broker 2, Replica: Broker 3  
- Partition 2 → Leader: Broker 3, Replica: Broker 1  

#### Как работают брокеры:
1. **Производитель отправляет сообщение**:
   - Производитель отправляет сообщение в определённый топик. Kafka определяет, какой брокер обслуживает партицию, в которую попадёт сообщение.
   - Например, сообщение с ключом `Order123` попадёт в Partition 0, которая управляется Broker 1.
2. **Брокеры обеспечивают репликацию**:
   - Лидер партиции (например, Broker 1 для Partition 0) записывает сообщение, а затем оно реплицируется на другие брокеры, которые хранят копии.
3. **Потребитель запрашивает данные**:
   - Потребители обращаются только к брокеру-лидеру для чтения сообщений из партиции.

#### Управление брокерами:
- **Добавление брокера в кластер**:
  - Вы можете масштабировать кластер, добавляя новые брокеры. Kafka автоматически перераспределяет данные.
- **Мониторинг состояния**:
  - Используйте инструменты, такие как Kafka Manager, Prometheus или Grafana, чтобы отслеживать производительность и здоровье брокеров.
- **Распределение нагрузки**:
  - Kafka поддерживает ребалансировку партиций, чтобы избежать перегрузки одного из брокеров.

#### Важность брокеров:
- **Масштабирование системы**: добавление брокеров помогает распределить данные и запросы при увеличении нагрузки на Kafka.
- **Повышение отказоустойчивости**: репликация между брокерами защищает от потери данных при сбое одного из узлов.
- **Оптимизация производительности**: понимание того, как брокеры управляют данными, позволяет правильно настраивать количество партиций и реплик.

---

### 4. Продюсеры и Консьюмеры

- **Производители (Producers)**: отправляют сообщения в определённые топики.
- **Потребители (Consumers)**: читают сообщения из топиков с использованием групп потребителей.

Продюсеры и консюмеры — это ключевые участники в экосистеме Apache Kafka, обеспечивающие запись и чтение сообщений из топиков.

---

#### Продюсеры (Producers)

Продюсер — это клиент, который отправляет данные (сообщения) в определённый топик в Kafka.

##### Как работают продюсеры:
1. **Выбор топика**:
   - Продюсер отправляет сообщение в указанный топик.
   - Если топик не существует и разрешено его создание, Kafka создаёт его автоматически.
2. **Определение партиции**:
   - Kafka решает, в какую партицию топика записывать сообщение:
     - Если указан ключ сообщения, партиция выбирается на основе хэш-функции от ключа.
     - Если ключ не указан, Kafka равномерно распределяет сообщения по партициям.
3. **Отправка данных**:
   - Продюсер отправляет данные брокеру, который является лидером для соответствующей партиции.
   - Сообщение реплицируется на другие брокеры для обеспечения отказоустойчивости.
4. **Подтверждение (Acknowledgment)**:
   - Продюсер может ждать подтверждения (`ack`) от Kafka перед записью следующего сообщения:
     - `acks=0`: Продюсер не ждёт подтверждений (самая быстрая, но ненадёжная конфигурация).
     - `acks=1`: Подтверждение приходит от лидера партиции.
     - `acks=all`: Подтверждение приходит после репликации сообщения на все брокеры.

---

#### Консюмеры (Consumers)

Консюмер — это клиент, который считывает данные из топиков Kafka.

##### Как работают консюмеры:
1. **Подключение к топику**:
   - Консюмер подписывается на один или несколько топиков.
2. **Обработка партиций**:
   - Каждая партиция топика назначается одному консюмеру в группе (consumer group). Это обеспечивает параллельную обработку данных.
3. **Чтение данных**:
   - Консюмер читает данные в порядке их записи (последовательно).
   - Для контроля прогресса чтения используется `offset` — уникальный идентификатор каждого сообщения в партиции.
4. **Подтверждение обработки**:
   - Консюмер может явно подтверждать обработку сообщений, чтобы Kafka знала, что их можно считать обработанными.

#### Особенности консюмеров:
- **Consumer Group**:
  - Консюмеры объединяются в группы для обработки данных.
  - Kafka гарантирует, что каждую партицию обрабатывает только один консюмер в группе.
- **Автокоммит Offset**:
  - Kafka автоматически сохраняет, до какого сообщения консюмер дочитал, если включен автокоммит.
- **Модели обработки**:
  - **At least once**: Сообщение может быть обработано более одного раза (надёжно, но не идеально для уникальности).
  - **Exactly once**: Каждое сообщение обрабатывается ровно один раз (поддерживается через Kafka Streams).
  - **At most once**: Сообщение может быть пропущено (быстро, но ненадёжно).

#### Основные отличия между продюсерами и консюмерами:

| Характеристика      | Продюсер (Producer)        | Консюмер (Consumer)       |
|---------------------|----------------------------|---------------------------|
| **Роль**            | Записывает данные в топики | Читает данные из топиков  |
| **Куда обращается** | К брокерам Kafka           | К брокерам Kafka          |
| **Выбор партиции**  | Определяет партицию для записи | Партиция назначается консюмеру |
| **Ключевой элемент**| Сообщения (messages)       | Offset (смещение)         |
| **Гарантии доставки**| Зависит от настроек `acks`| Зависит от модели обработки |

#### Взаимодействие продюсеров и консюмеров:
1. Продюсер публикует сообщения в топик (например, `orders`).
2. Kafka распределяет сообщения между партициями и реплицирует их.
3. Консюмеры в группе (например, `order_processor_group`) читают и обрабатывают сообщения из каждой партиции.

---

### Роль Zookeeper в Kafka

**Zookeeper** — это централизованная система управления, необходимая для работы Kafka (в старых версиях). Начиная с версии Kafka 2.8+, поддерживается встроенная система консенсуса **Kafka Raft**.

#### Для чего используется Zookeeper:
1. **Управление метаданными**:  
   - Хранит данные о кластере Kafka, такие как информация о топиках, партициях и брокерах.---
2. **Выбор лидеров**:  
   - Назначает брокеров-лидеров для партиций топиков.
3. **Обеспечение синхронизации**:  
   - Гарантирует, что все брокеры имеют согласованное представление о состоянии кластера.
4. **Мониторинг узлов**:  
   - Отслеживает работоспособность брокеров и узлов.

#### Почему Kafka уходит от Zookeeper:
- **Сложности управления**: Zookeeper сложен в управлении, особенно для больших кластеров.
- **Kafka Raft**: встроенная система консенсуса заменяет Zookeeper, делая кластеры Kafka более автономными и простыми в эксплуатации.

### Почему использовать Kafka?

1. **Обработка данных в реальном времени**:  
   Kafka идеально подходит для аналитики и реактивных приложений.

2. **Интеграция данных**:  
   Kafka соединяет различные системы через централизованное место, упрощая обмен данными.

3. **Надежность**:  
   Благодаря репликации данные не теряются даже при сбоях, обеспечивая высокую отказоустойчивость.

---

### Аналоги Apache Kafka

#### 1. RabbitMQ
- **Что это?**  
  RabbitMQ — это традиционная система обмена сообщениями, основанная на стандарте AMQP (Advanced Message Queuing Protocol).
- **Ключевые особенности**:
  - Поддержка сложных шаблонов маршрутизации (например, через exchange).
  - Отлично справляется с очередями, требующими подтверждения доставки сообщений (ACK).
  - Сообщения могут храниться длительное время, если потребители не забирают их.
- **Отличия от Kafka**:
  - RabbitMQ лучше подходит для сценариев с небольшим объёмом данных и сложной маршрутизацией.
  - Kafka лучше справляется с потоковой обработкой больших объёмов данных.
- **Когда применять**:
  - Для систем с высокой потребностью в подтверждении доставки сообщений.
  - В микросервисной архитектуре для управления очередями.
#### 2. Amazon Kinesis
- **Что это?**  
  Kinesis — это облачная платформа потоковой обработки от Amazon Web Services (AWS).
- **Ключевые особенности**:
  - Интеграция с AWS-сервисами (S3, Lambda, Redshift).
  - Обеспечивает низкую задержку для потоковой обработки.
  - Полностью управляемая облачная платформа.
- **Отличия от Kafka**:
  - Kinesis не требует администрирования, в отличие от Kafka, который требует настройки и управления кластером.
  - Kafka предоставляет больше гибкости и подходит для использования в локальных инфраструктурах.
- **Когда применять**:
  - Если вы уже работаете с AWS и хотите минимизировать административные задачи.
  - Для простых сценариев потоковой обработки с высокой масштабируемостью.
#### 3. Pulsar (Apache Pulsar)
- **Что это?**  
  Pulsar — это распределённая система обмена сообщениями и потоков данных от Apache.
- **Ключевые особенности**:
  - Поддержка многокластерного реплицирования.
  - Единая система для очередей и потоков данных.
  - Встроенная поддержка многотенантности.
- **Отличия от Kafka**:
  - Pulsar может объединять очереди и потоковые данные, в то время как Kafka лучше подходит для потоковой обработки.
  - Pulsar обеспечивает более сложное управление топиками и партициями.
- **Когда применять**:
  - Для систем с требованиями к многокластерному управлению.
  - Если требуется гибкость в управлении очередями и потоками.
#### 4. Google Pub/Sub
- **Что это?**  
  Google Pub/Sub — это облачная система обмена сообщениями от Google Cloud Platform.
- **Ключевые особенности**:
  - Поддерживает масштабируемую потоковую передачу данных в реальном времени.
  - Полностью управляемая система.
  - Отлично интегрируется с другими сервисами Google Cloud.
- **Отличия от Kafka**:
  - Kafka требует управления кластером, в то время как Pub/Sub полностью управляется провайдером.
  - Kafka предлагает более низкую задержку для высоконагруженных систем.
- **Когда применять**:
  - Если вы уже используете Google Cloud.
  - Для простых задач обмена сообщениями без необходимости в тонкой настройке.
#### 5. Redpanda
- **Что это?**  
  Redpanda — это современная альтернатива Kafka, написанная на C++ с упором на высокую производительность.
- **Ключевые особенности**:
  - Полная совместимость с Kafka API.
  - Более высокая производительность благодаря отсутствию Zookeeper.
  - Простота установки и администрирования.
- **Отличия от Kafka**:
  - Redpanda работает быстрее на низкопроизводительном оборудовании.
  - Kafka предлагает больше гибкости и зрелости в экосистеме.
- **Когда применять**:
  - Для высоконагруженных систем, где важна производительность.
  - Если требуется альтернатива Kafka без необходимости управления Zookeeper.
#### 6. ActiveMQ
- **Что это?**  
  ActiveMQ — это традиционная очередь сообщений с поддержкой протоколов, таких как AMQP, MQTT, STOMP.
- **Ключевые особенности**:
  - Хорошо подходит для транзакционных систем.
  - Простота интеграции с Java-приложениями.
- **Отличия от Kafka**:
  - ActiveMQ ориентирован на сценарии с меньшим объёмом данных.
  - Kafka лучше подходит для потоковой обработки и анализа больших данных.
- **Когда применять**:
  - Для приложений, которые используют стандартные протоколы (например, MQTT).
  - В небольших проектах или системах с низкой нагрузкой.
#### 7. Azure Event Hubs
- **Что это?**  
  Event Hubs — это облачная платформа для потоков данных в реальном времени от Microsoft Azure.
- **Ключевые особенности**:
  - Масштабируемость для обработки миллионов событий в секунду.
  - Глубокая интеграция с экосистемой Azure.
- **Отличия от Kafka**:
  - Event Hubs лучше подходит для пользователей Azure.
  - Kafka предоставляет больше возможностей для кастомизации и локальных решений.
- **Когда применять**:
  - Для потоковой обработки в облачных решениях на базе Azure.


### Как выбрать инструмент?

| **Сценарий**                            | **Инструмент**   | **Причина**                                     |
|------------------------------------------|------------------|------------------------------------------------|
| Обработка больших данных в реальном времени | Kafka            | Высокая производительность и масштабируемость. |
| Микросервисы и сложная маршрутизация     | RabbitMQ         | Отличная поддержка обмена сообщениями.         |
| Простая потоковая обработка в AWS        | Amazon Kinesis   | Интеграция с сервисами AWS и минимальные затраты на управление. |
| Гибкость в очередях и потоках            | Apache Pulsar    | Поддержка многотенантности и сложных сценариев.|
| Облачная потоковая обработка             | Google Pub/Sub   | Простота использования и интеграция с Google Cloud. |
| Высокая производительность               | Redpanda         | Совместимость с Kafka и высокая скорость.      |
| Поддержка стандартных протоколов         | ActiveMQ         | Лёгкость интеграции с существующими системами. |
