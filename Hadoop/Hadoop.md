# Hadoop

Hadoop — это фреймворк для распределенной обработки больших данных (Big Data), который работает на кластерах серверов. Он основан на парадигме MapReduce и предназначен для масштабирования от одного сервера до тысяч узлов, где каждый узел выполняет хранение и вычисления.

<image src="https://github.com/NikGerasimovich/Data-engineering/blob/main/Hadoop/IMAGE/Hadoop-Ecosystem.webp" alt="Hadoop">


## Основные компоненты Hadoop

### 1. HDFS (Hadoop Distributed File System)
HDFS — это распределённая файловая система, которая хранит данные на нескольких узлах.

#### Особенности:
- Разделение файлов на блоки (обычно по 128 MB или 256 MB).
- Дублирование данных (обычно 3 копии) для обеспечения отказоустойчивости.
- Мастер-узел (NameNode) управляет метаданными, рабочие узлы (DataNode) хранят данные.

#### Преимущества:
- Работа с очень большими файлами.
- Высокая отказоустойчивость благодаря репликации.

### 2. YARN (Yet Another Resource Negotiator)
YARN управляет ресурсами кластера и планирует выполнение задач.

#### Компоненты:
- **ResourceManager**: отвечает за распределение ресурсов.
- **NodeManager**: управляет ресурсами на каждом узле.
- **ApplicationMaster**: контролирует выполнение приложений.

### 3. MapReduce
MapReduce — это программная модель обработки данных, которая работает по принципу "разделяй и властвуй".

#### Этапы:
1. **Map**: разбивает данные на небольшие части и выполняет параллельную обработку.
2. **Reduce**: объединяет результаты Map для получения итогового результата.

### 4. Hadoop Common
Набор библиотек и утилит, которые поддерживают работу других компонентов Hadoop.

## Экосистема Hadoop

Помимо ядра Hadoop, существует богатая экосистема инструментов для работы с большими данными:

1. **Apache Hive**  
   Язык SQL-подобных запросов для анализа данных, хранящихся в HDFS.  
   Компилирует запросы в MapReduce задачи.

2. **Apache Pig**  
   Язык высокого уровня для анализа данных (Pig Latin).  
   Подходит для более сложных вычислений, чем SQL.

3. **Apache HBase**  
   Распределённая база данных, построенная поверх HDFS.  
   Поддерживает случайный доступ к данным и работает в режиме NoSQL.

4. **Apache Spark**  
   Фреймворк для распределённой обработки данных с использованием in-memory вычислений.  
   Более быстр, чем MapReduce, особенно для итеративных задач.

5. **Apache Zookeeper**  
   Система координации для управления кластерами.

6. **Apache Oozie**  
   Система планирования задач для автоматизации рабочих процессов Hadoop.

7. **Apache Flume**  
   Инструмент для сбора и агрегации потоковых данных в HDFS.

8. **Apache Sqoop**  
   Используется для передачи данных между HDFS и реляционными базами данных.

## Преимущества Hadoop
- **Масштабируемость**: легко добавлять новые узлы в кластер.
- **Отказоустойчивость**: репликация данных обеспечивает надёжность.
- **Экономичность**: можно использовать недорогие сервера.
- **Универсальность**: подходит для хранения и анализа различных типов данных.

## Недостатки Hadoop
- **Высокие задержки**: MapReduce не подходит для задач реального времени.
- **Сложность настройки**: требует значительных усилий для развертывания и администрирования.
- **Ограничения HDFS**: неэффективно для работы с малыми файлами.

## Сценарии использования Hadoop
- **Обработка больших данных**: анализ журналов веб-сайтов, кликстримы.
- **Машинное обучение**: обработка огромных наборов данных для построения моделей.
- **ETL-процессы**: извлечение, преобразование и загрузка данных.
- **Хранилища данных (Data Lake)**: центральное место для хранения структурированных и неструктурированных данных.
 
 ---

# Hadoop Distributed File System (HDFS)

HDFS — это распределённая файловая система, которая является основой Hadoop. Она разработана для хранения огромных объёмов данных и обеспечения быстрого доступа к этим данным на кластере серверов.

<image src="https://github.com/NikGerasimovich/Data-engineering/blob/main/Hadoop/IMAGE/HDFS.png" alt="HDFS">


## Основные характеристики HDFS

### Разделение данных на блоки (Block Storage)
- **Размер блока**: Обычно 128 MB или 256 MB, хотя это значение можно настроить.
- **Разделение**: Большой файл делится на блоки фиксированного размера, которые хранятся на разных узлах (DataNodes).

### Репликация данных (Replication)
- **По умолчанию**: 3 копии каждого блока.
- **Цель**: Повышение отказоустойчивости и доступности данных. Если один узел выходит из строя, данные доступны на других узлах.

### Работа с большими файлами
HDFS оптимизирован для последовательного чтения и записи больших файлов.

### Неизменяемость данных
- **Модель**: "Write Once, Read Many".
- **Особенности**: Данные в HDFS считаются неизменяемыми после записи. Изменить файл нельзя, но его можно перезаписать или удалить.

## Архитектура HDFS

### 1. NameNode (Мастер-узел)
- **Роль**: Управляет метаданными, такими как:
  - Расположение блоков.
  - Доступные DataNodes.
  - Состояние файловой системы.
- **Функции**:
  - Отвечает за маршрутизацию операций чтения и записи.
  - Хранит в оперативной памяти дерево файловой системы и сопоставление файлов с их блоками.
- **Отказоустойчивость**: Используется резервный NameNode (Standby NameNode) для автоматического переключения в случае сбоя.

### 2. DataNode (Рабочие узлы)
- **Роль**: Хранят сами данные. Каждый DataNode отвечает за управление блоками, которые он хранит.
- **Функции**:
  - Регулярно отправляют отчёты о состоянии (heartbeat) NameNode.
  - Обрабатывают запросы на чтение и запись данных от клиентов.

### 3. Secondary NameNode
- **Роль**: Не является резервной копией NameNode. Вместо этого периодически сливает журнал операций (edit log) и снимок состояния файловой системы (fsimage) для снижения нагрузки на NameNode.

## Потоки данных в HDFS

### 1. Чтение данных
1. Клиент запрашивает данные у NameNode.
2. NameNode сообщает, на каких DataNodes хранятся блоки.
3. Клиент обращается к соответствующим DataNodes для чтения данных.

### 2. Запись данных
1. Клиент запрашивает у NameNode место для записи.
2. NameNode выбирает DataNodes для размещения блоков с учётом репликации.
3. Клиент передаёт данные на первый DataNode, который реплицирует их на другие узлы.

## Преимущества HDFS

- **Масштабируемость**: Поддерживает масштабирование от одного сервера до тысяч узлов.
- **Высокая отказоустойчивость**: Благодаря репликации данные доступны даже при сбое нескольких узлов.
- **Экономичность**: Позволяет использовать недорогие аппаратные решения (commodity hardware).
- **Гибкость**: Поддержка различных типов данных: структурированных, полуструктурированных и неструктурированных.
- **Эффективность работы с большими файлами**: Оптимизация для последовательного доступа делает его идеальным для больших объёмов данных.

## Недостатки HDFS

- **Неэффективность для мелких файлов**: Каждый файл требует записи метаданных, что создаёт нагрузку на NameNode.
- **Ограниченная неизменяемость данных**: Нельзя изменять данные после записи.
- **Зависимость от NameNode**: NameNode является единой точкой отказа, хотя использование резервного Standby NameNode снижает этот риск.
- **Высокие задержки при случайном доступе**: Не подходит для приложений, которые требуют случайного чтения небольших фрагментов данных.

## Ключевые сценарии использования HDFS

- **Хранилище больших данных (Data Lake)**: Сохранение структурированных и неструктурированных данных для дальнейшего анализа.
- **Обработка больших данных**: Используется совместно с инструментами, такими как Apache Hive, Pig и Spark.
- **Журналы и архивы**: Сохранение данных из логов серверов и приложений.
- **Анализ потоков данных**: Использование Flume или Kafka для передачи данных в HDFS и последующего анализа.

---

# Apache Hadoop YARN (Yet Another Resource Negotiator)

YARN — это система управления ресурсами и выполнения задач в экосистеме Hadoop. Она позволяет различным приложениям использовать общий кластер Hadoop, эффективно распределяя вычислительные ресурсы и обеспечивая параллельную обработку данных.

<image src="https://github.com/NikGerasimovich/Data-engineering/blob/main/Hadoop/IMAGE/YARN.webp" alt="YARN">


## Основные функции YARN

### Управление ресурсами
- Распределяет ресурсы (процессорное время, оперативная память и т. д.) между различными приложениями.
- Оптимизирует использование кластеров.

### Планирование задач
- Обеспечивает очереди задач и их выполнение в зависимости от приоритетов, доступных ресурсов и требований приложений.

### Поддержка нескольких типов приложений
- Помимо MapReduce, поддерживает другие вычислительные движки, такие как Apache Spark, Apache Flink, Tez, Storm и HBase.

## Архитектура YARN

YARN состоит из трёх основных компонентов:

### 1. ResourceManager (Менеджер ресурсов)
Центральный компонент, управляющий распределением ресурсов в кластере.

#### Состоит из двух модулей:
- **Scheduler (Планировщик)**:
  - Отвечает за распределение ресурсов между приложениями.
  - Не отслеживает статус задачи или её завершение.
- **ApplicationsManager (Менеджер приложений)**:
  - Управляет жизненным циклом приложений.
  - Отвечает за запуск контейнеров ApplicationMaster и отслеживание их завершения.

### 2. NodeManager (Узел-менеджер)
- Работает на каждом узле в кластере.
- **Отвечает за**:
  - Мониторинг ресурсов узла.
  - Управление контейнерами, запускаемыми на узле.
  - Сообщение о статусе работы узла ResourceManager.

### 3. ApplicationMaster (Мастер приложений)
- Создаётся для каждого приложения.
- **Отвечает за**:
  - Координацию выполнения задач приложения.
  - Запрос ресурсов у ResourceManager.
  - Запуск контейнеров на NodeManager.

### 4. Container (Контейнер)
- Единица вычислительных ресурсов, выделяемая YARN.
- Содержит CPU, память и другие ресурсы, необходимые для выполнения задачи.

## Потоки данных и выполнения задач

### 1. Инициация приложения
1. Клиент отправляет запрос на запуск приложения в ResourceManager.
2. ResourceManager запускает ApplicationMaster для управления приложением.

### 2. Запрос ресурсов
1. ApplicationMaster запрашивает ресурсы у ResourceManager.
2. Планировщик распределяет ресурсы и уведомляет ApplicationMaster.

### 3. Выполнение задачи
1. ApplicationMaster запускает задачи в выделенных контейнерах на NodeManager.
2. NodeManager выполняет задачи и отправляет статус выполнения ApplicationMaster.

### 4. Завершение приложения
- После завершения всех задач ApplicationMaster сообщает ResourceManager о завершении работы.

## Преимущества YARN

- **Гибкость**:
  - Поддержка различных фреймворков обработки данных.
  - Возможность запускать как пакетные, так и стриминговые приложения.
- **Масштабируемость**:
  - Обеспечивает обработку тысяч узлов в одном кластере.
- **Улучшенное использование ресурсов**:
  - Эффективное распределение памяти и процессорного времени между приложениями.
- **Отделение управления ресурсами от вычислений**:
  - Упрощает разработку новых приложений.
- **Устойчивость к сбоям**:
  - Встроенные механизмы обнаружения и восстановления после сбоев.

## Недостатки YARN

- **Сложность настройки**:
  - Требуется тонкая настройка параметров для оптимального использования ресурсов.
- **Зависимость от ResourceManager**:
  - Single point of failure, если не используется High Availability.
- **Нагрузка на ResourceManager**:
  - Высокий объём запросов от приложений может вызвать задержки.
- **Масштабируемость с учётом мелких задач**:
  - YARN неэффективно работает с большим количеством небольших задач, так как накладные расходы на запуск контейнеров могут быть значительными.

## Применение YARN

- **Обработка больших данных**:
  - Используется в Hadoop для выполнения MapReduce, Spark, Flink и других рабочих нагрузок.
- **Мультизадачность в кластере**:
  - Одновременное выполнение нескольких приложений и рабочих нагрузок.
- **Поддержка данных в реальном времени**:
  - Использование стриминговых систем, таких как Kafka или Storm, совместно с YARN.

## Настройка YARN

### Конфигурационные файлы:
- `yarn-site.xml`: Основной файл для настройки параметров YARN.
- `core-site.xml`: Общие параметры кластера.

### Основные параметры настройки:

#### Ресурсы узлов:
- `yarn.nodemanager.resource.memory-mb` — доступная память.
- `yarn.nodemanager.resource.cpu-vcores` — доступные CPU.

#### Контейнеры:
- `yarn.scheduler.minimum-allocation-mb` — минимальная память контейнера.
- `yarn.scheduler.maximum-allocation-mb` — максимальная память контейнера.

---

# Apache Hadoop MapReduce

**MapReduce** — это программная модель и основной механизм обработки данных в экосистеме Hadoop. Она предназначена для обработки и генерации больших объёмов данных параллельно в распределённой вычислительной среде.

<image src="https://github.com/NikGerasimovich/Data-engineering/blob/main/Hadoop/IMAGE/MapReduce0.png" alt="MapReduce">


---

## Основные этапы MapReduce

MapReduce состоит из двух ключевых фаз: **Map** и **Reduce**. Между ними выполняются дополнительные процессы **Shuffle** и **Sort**, которые обеспечивают корректность и эффективность выполнения.

### 1. Map (Маппинг)
- Входные данные делятся на небольшие фрагменты (*сплиты*).
- Каждый сплит передаётся в функцию `Map`, которая обрабатывает данные и преобразует их в пары ключ-значение `(key, value)`.

### 2. Shuffle (Перемешивание)
- После стадии `Map` происходит сортировка и группировка пар `(key, value)`.
- Все пары с одинаковыми ключами собираются вместе и передаются на стадию `Reduce`.

### 3. Reduce (Сокращение)
- Функция `Reduce` принимает сгруппированные данные и выполняет над ними операции, например, агрегирование или фильтрацию.

---

## Архитектура MapReduce

### JobTracker (в старых версиях Hadoop)
- Управляет выполнением задания (*Job*).
- Распределяет задачи (*Tasks*) между узлами.
- Следит за прогрессом выполнения и перезапускает задачи в случае сбоев.

### TaskTracker (в старых версиях Hadoop)
- Работает на каждом узле.
- Выполняет задачи `Map` и `Reduce`, выделенные для этого узла.
- Сообщает о статусе выполнения `JobTracker`.

> С версии Hadoop 2.x функции `JobTracker` и `TaskTracker` заменены на **YARN ResourceManager** и **NodeManager**, что обеспечивает более гибкое управление ресурсами.

### InputSplit
- Делит входные данные на равные части.
- Каждая часть обрабатывается отдельным экземпляром функции `Map`.

### OutputFormat
- Определяет формат вывода данных.
- Чаще всего используется текстовый формат, но возможны и другие, например, **SequenceFile**.

---

## Поток выполнения MapReduce

1. **Подготовка данных**  
   Входные данные загружаются в HDFS. Указывается путь к данным и их формат (например, текстовые файлы).

2. **Инициация задачи**  
   Программа отправляет задание `JobTracker` (или `ResourceManager` в YARN). `JobTracker` распределяет задачи `Map` и `Reduce` между узлами.

3. **Выполнение Map задач**  
   Каждая задача `Map` обрабатывает свой `InputSplit` и генерирует пары `(key, value)`.

4. **Перемешивание и сортировка**  
   Пары `(key, value)` сортируются и группируются по ключу. Пары с одинаковым ключом передаются на соответствующую задачу `Reduce`.

5. **Выполнение Reduce задач**  
   Задачи `Reduce` обрабатывают сгруппированные пары `(key, list_of_values)` и генерируют финальные результаты.

6. **Запись результатов**  
   Результаты сохраняются в HDFS или другом указанном месте.

---

## Преимущества MapReduce

- **Масштабируемость**  
  Эффективно обрабатывает большие объёмы данных, распределяя задачи между узлами кластера.

- **Терпимость к сбоям**  
  В случае отказа узла задачи автоматически перезапускаются на другом узле.

- **Параллелизм**  
  Использует распределённую обработку, что значительно ускоряет выполнение задач.

- **Универсальность**  
  Подходит для обработки структурированных, полуструктурированных и неструктурированных данных.

- **Автоматизация распределения данных**  
  HDFS и MapReduce автоматически распределяют и реплицируют данные между узлами.

---

## Недостатки MapReduce

- **Высокая задержка**  
  Подходит для пакетной обработки, но неэффективен для задач реального времени.

- **Сложность разработки**  
  Требует понимания концепции ключей и значений, а также хороших знаний Java.

- **Низкая производительность для сложных запросов**  
  Неэффективен для многократных запросов к одним и тем же данным.

- **Накладные расходы на ввод и вывод**  
  Постоянная запись промежуточных результатов на диск снижает производительность.

---

## Примеры использования MapReduce

1. **Поиск слова в текстовых данных**  
   - *Map:* Разбить текст на слова, назначить каждому слову значение 1.  
   - *Reduce:* Подсчитать количество повторений каждого слова.

2. **Обработка логов**  
   - *Map:* Разобрать строки логов, извлекая ключевые параметры (например, IP-адрес).  
   - *Reduce:* Подсчитать количество запросов с каждого IP.

3. **Анализ продаж**  
   - *Map:* Группировка данных о продажах по региону.  
   - *Reduce:* Суммирование доходов по каждому региону.

---

## MapReduce vs Современные технологии

Современные инструменты, такие как **Apache Spark** и **Apache Flink**, предоставляют более быстрые и удобные альтернативы благодаря **in-memory** обработке и простому API. Однако **MapReduce** продолжает использоваться там, где важны надёжность и простота интеграции в экосистему Hadoop.

---

# Сравнение HDFS, YARN и MapReduce

| **Характеристика**           | **HDFS (Hadoop Distributed File System)**                  | **YARN (Yet Another Resource Negotiator)**                  | **MapReduce (Модель обработки данных)**                    |
|-------------------------------|-----------------------------------------------------------|-------------------------------------------------------------|------------------------------------------------------------|
| **Назначение**               | Хранение больших объёмов данных в распределённой среде.   | Управление ресурсами и планирование выполнения задач в кластере. | Модель программирования для обработки больших данных.      |
| **Роль в экосистеме Hadoop** | Базовое хранилище данных.                                 | Фреймворк для управления вычислительными ресурсами.         | Механизм обработки данных, выполняющий задачи Map и Reduce. |
| **Функциональность**         | - Репликация данных для отказоустойчивости.<br>- Разделение файлов на блоки для хранения на нескольких узлах. | - Распределение ресурсов между задачами.<br>- Планирование выполнения задач. | - Параллельная обработка больших объёмов данных.<br>- Сочетание пакетной обработки с распределённой архитектурой. |
| **Основные компоненты**      | - NameNode<br>- DataNode                                  | - ResourceManager<br>- NodeManager                          | - JobTracker/TaskTracker (до Hadoop 2.x)<br>- Map задачи<br>- Reduce задачи |
| **Поддержка отказоустойчивости** | - Репликация данных (по умолчанию 3 копии).<br>- Автоматическое восстановление данных на новых узлах. | - Перезапуск задач в случае сбоя.<br>- Контроль доступности ресурсов. | - Повторное выполнение задач в случае сбоя (на других узлах). |
| **Тип данных**               | Любые форматы данных (структурированные, полуструктурированные, неструктурированные). | Метаданные о задачах и состоянии ресурсов.                  | Входные данные в формате ключ-значение `(key, value)`.     |
| **Обработка данных**         | Не обрабатывает данные, только хранит.                   | Не обрабатывает данные, управляет ресурсами.                | Обрабатывает данные с использованием двух фаз: Map и Reduce. |
| **Основной язык реализации** | Java                                                     | Java                                                       | Java (или другие языки через API, такие как Python, C++).  |
| **Поддерживаемая нагрузка**  | - Подходит для хранения данных с высокой пропускной способностью. | - Поддерживает высокую конкуренцию за ресурсы.              | - Пакетная обработка больших объёмов данных.               |
| **Примеры использования**    | - Хранение данных для аналитики.<br>- Архивирование логов.<br>- Хранилище для Data Lake. | - Управление задачами Spark, MapReduce и другими фреймворками. | - Анализ больших объёмов данных, таких как логи, текстовые файлы и бизнес-отчёты. |
| **Недостатки**               | - Только хранилище, без встроенной аналитики.<br>- Требуется отдельный механизм обработки. | - Требует сложной настройки и мониторинга.<br>- Зависит от производительности узлов. | - Высокая задержка.<br>- Сложность разработки и поддержки кода.<br>- Запись промежуточных данных на диск. |

---

## Итоги

- **HDFS**: Основное хранилище для больших данных в распределённой среде.  
- **YARN**: Платформа управления ресурсами и планирования выполнения задач.  
- **MapReduce**: Традиционная модель обработки данных в Hadoop. Несмотря на эффективность работы с большими объёмами данных, популярность MapReduce снижается из-за появления более быстрых решений, таких как Apache Spark и Flink.
